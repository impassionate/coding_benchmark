# coding_benchmark

A benchmark with 100 GPT_Generated python coding problems (mostly closely related to reeal life) with a specific grading standard that can be used to assess a generative AI's coding abilities in different aspects. <br />
The coding problems are divided into 4 parts: <br />1. Error/Edge cases handling; <br />2. Task Planning Ability; <br />3. Optimization Ability; <br />4. Regular General Test. <br />
Each part is divided into 3 levels of difficulties (easy-beginner level; medium-intermediate level; hard-expert level)



## Section Description

- Error/Edge cases handling: used mainly to test if the AI can thoroughly handle all edge cases and error inputs
- Task Planning: In this section, we are focusing on testing if the AI has 
- [Contributing](#contributing)
- [License](#license)

## Installation

Detailed instructions on how to install, setup, and get the project running.

1. Clone the repo
